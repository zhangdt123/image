import os
import torch
import torch.nn as nn
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import pandas as pd
import numpy as np
from tqdm import tqdm

# ====== é…ç½® ======
class Config:
    model_path = "moe_model_best5.pth"
    generated_dir = "imageclef data/generated"
    real_unknown_dir = "imageclef data/real_unknown"
    output_csv = "run.csv"
    input_size = 224
    batch_size = 64
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    threshold = 0.62  # ç›¸ä¼¼åº¦é˜ˆå€¼

# ====== æ¨¡å‹ç»“æ„å¯¼å…¥ ======
from tran31  import MOEContrastiveModel  # ä¿è¯ train.py ä¸­æ¨¡å‹ç»“æ„æ²¡å˜

# ====== å›¾åƒæ•°æ®é›†ç±» ======
class ImageDataset(Dataset):
    def __init__(self, image_dir):
        self.paths = [os.path.join(image_dir, f) for f in sorted(os.listdir(image_dir))]
        self.filenames = [os.path.basename(p) for p in self.paths]
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(Config.input_size),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ])

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert("RGB")
        return self.transform(img), self.filenames[idx]

# ====== ç‰¹å¾æå–å‡½æ•° ======
def extract_features(model, dataloader):
    features, names = [], []
    with torch.no_grad():
        for imgs, fnames in tqdm(dataloader):
            imgs = imgs.to(Config.device)
            feats, _ = model.momentum_forward(imgs)
            features.append(feats.cpu())
            names.extend(fnames)
    return torch.cat(features, dim=0), names

# ====== ä¸»æµç¨‹ ======
def main():
    print("ğŸ” åŠ è½½æ¨¡å‹...")
    model = MOEContrastiveModel()
    model.load_state_dict(torch.load(Config.model_path, map_location="cpu"))
    model = model.to(Config.device).eval()

    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    gen_loader = DataLoader(ImageDataset(Config.generated_dir), batch_size=Config.batch_size, shuffle=False)
    real_loader = DataLoader(ImageDataset(Config.real_unknown_dir), batch_size=Config.batch_size, shuffle=False)

    print("ğŸ§  æå–ç”Ÿæˆå›¾ç‰¹å¾...")
    gen_feats, _ = extract_features(model, gen_loader)  # shape: [N_gen, D]

    print("ğŸ§  æå–çœŸå®å›¾ç‰¹å¾...")
    real_feats, real_names = extract_features(model, real_loader)  # shape: [N_real, D]

    print("ğŸ“ è®¡ç®—ç›¸ä¼¼åº¦...")
    sim_matrix = torch.mm(gen_feats, real_feats.T).numpy()  # shape: [N_gen, N_real]
    max_sim = np.max(sim_matrix, axis=0)  # æ¯å¼  real å›¾ä¸æ‰€æœ‰ gen å›¾çš„æœ€å¤§ç›¸ä¼¼åº¦

    print("ğŸ§ª åˆ¤å®šæ˜¯å¦å‚ä¸ç”Ÿæˆ...")
    labels = (max_sim >= Config.threshold).astype(int)

    print("ğŸ’¾ å†™å…¥ CSV...")
    pd.DataFrame({
        "original_image": real_names,
        "label": labels
    }).to_csv(Config.output_csv, index=False)
    print(f"âœ… æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ {Config.output_csv}")

if __name__ == "__main__":
    main()
